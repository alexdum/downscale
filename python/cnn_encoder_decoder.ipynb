{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d08d994-b39c-4c60-9bca-276262473d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 12:11:57.405343: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-25 12:11:57.422783: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-25 12:11:57.428049: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-25 12:11:59.025567: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import zarr\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import jax\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "jax.random.PRNGKey(SEED)\n",
    "\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir('/data/keeling/a/ad87/downscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf0b9e2-b31a-45e6-9a40-390595e76247",
   "metadata": {},
   "source": [
    "#### Data Handling: Load and Resample Data\n",
    "We will load the CMIP6 data and the GMFD observational data. Weâ€™ll resample the GMFD data to the CMIP6 resolution (e.g., ~100 km) to use as the target during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd37a02c-31f7-4817-b31f-9a8e432f431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CMIP6 raw data (predictor variables)\n",
    "cmip6_data_path = '/data/cristi/a/cristi/downscaled_data/cmip6/raw/zarr/RO_CMIP6_raw/CNRM-ESM2-1/historical/r1i1p1f2/tas/tas_day_CNRM-ESM2-1_historical_r1i1p1f2_gr_1950_2014_rou.zarr'\n",
    "cmip6_data = xr.open_zarr(cmip6_data_path)\n",
    "\n",
    "# Load the GMFD reference observational data (target variable)\n",
    "gmfd_data_path = '/data/keeling/a/cristi/a/downscaled_data/gmfd/ncs/ro'\n",
    "gmfd_files = [f'{gmfd_data_path}/tas_daily_ro_{year}.nc' for year in range(1950, 2015)]\n",
    "gmfd_data = xr.open_mfdataset(gmfd_files, combine='by_coords')\n",
    "\n",
    "# Resample  CMIP6 to GMFD resolution (~25 km)\n",
    "target_lat = gmfd_data.lat\n",
    "target_lon = gmfd_data.lon\n",
    "cmip6_high_res = cmip6_data.interp(lat=target_lat, lon=target_lon, method='cubic', kwargs={\"fill_value\": \"extrapolate\"})\n",
    "\n",
    "\n",
    "# Normalize the data (standardization)\n",
    "def normalize(data):\n",
    "    mean = data.mean().compute().item()\n",
    "    std = data.std().compute().item()\n",
    "    return (data - mean) / std\n",
    "\n",
    "cmip6_data_norm = normalize(cmip6_high_res['tas'])\n",
    "gmfd_data_norm = normalize(gmfd_data['tas'])\n",
    "\n",
    "# Convert data to NumPy arrays for use in Keras\n",
    "cmip6_train = cmip6_data_norm.values\n",
    "gmfd_train = gmfd_data_norm.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1f081-cc7c-4180-91a7-6c03f40ab38a",
   "metadata": {},
   "source": [
    "#### Build the CNN Model (Keras with JAX Backend)\n",
    "Now let's define a simple CNN model using Keras with JAX backend. Our model will take the coarse-resolution CMIP6 data and predict the high-resolution GMFD data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4235968-0412-43be-9c5f-d69af71b3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Define the model architecture (as done earlier)\n",
    "n = 32  # base filter count\n",
    "input_shape = (cmip6_train.shape[1], cmip6_train.shape[2], 1)  # Assuming 1 channel (tas)\n",
    "\n",
    "def build_network(input_shape):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder with convolutional layers\n",
    "    x = inputs\n",
    "    skip_connections = []\n",
    "\n",
    "    # 31 convolutional layers, with filter numbers n, 2n, 4n and batch normalization\n",
    "    for i in range(31):\n",
    "        filters = n if i < 10 else (2 * n if i < 20 else 4 * n)\n",
    "        x = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        if i % 2 == 1:  # Every 2 convolutional layers, save skip connection\n",
    "            skip_connections.append(x)\n",
    "\n",
    "    # Decoder with upsampling layers and skip connections\n",
    "    for i in range(16):\n",
    "        filters = 4 * n if i < 6 else (2 * n if i < 12 else n)\n",
    "        x = layers.Conv2DTranspose(filters, kernel_size=3, strides=1, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        \n",
    "        if i < len(skip_connections):\n",
    "            skip_connection = skip_connections[-(i + 1)]\n",
    "            if skip_connection.shape[-1] != x.shape[-1]:  # Align the number of channels\n",
    "                skip_connection = layers.Conv2D(filters, kernel_size=1, strides=1, padding='same')(skip_connection)\n",
    "            x = layers.Add()([x, skip_connection])\n",
    "\n",
    "    # Final convolutional layer without activation\n",
    "    outputs = layers.Conv2D(1, kernel_size=1, strides=1, padding='same')(x)\n",
    "    \n",
    "    # Building the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build and compile model\n",
    "model = build_network(input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9a991-7308-4312-b209-c3fdc9c8c589",
   "metadata": {},
   "source": [
    "#### Split the data\n",
    "Train set: The first portion of the time period (e.g., 60-70% of the time series).\n",
    "Validation set: The next portion of the time series (e.g., the following 15-20% of the time series).\n",
    "Test set: The final portion of the time series (e.g., the last 15-20%): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fba81-bb74-4138-8fb9-34acc93ea69a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reshape data to add the channel dimension\n",
    "cmip6_train_reshaped = cmip6_train[..., np.newaxis]\n",
    "gmfd_train_reshaped = gmfd_train[..., np.newaxis]\n",
    "\n",
    "# Get the total number of time steps\n",
    "n_samples = cmip6_train_reshaped.shape[0]\n",
    "\n",
    "# Split indices based on time series order\n",
    "train_size = int(n_samples * 0.6)  # 60% for training\n",
    "val_size = int(n_samples * 0.2)    # 20% for validation\n",
    "test_size = n_samples - train_size - val_size  # Remainder for test\n",
    "print(train_size, val_size, test_size)\n",
    "\n",
    "# Split the data while preserving the temporal structure\n",
    "X_train = cmip6_train_reshaped[:train_size]\n",
    "y_train = gmfd_train_reshaped[:train_size]\n",
    "\n",
    "X_val = cmip6_train_reshaped[train_size:train_size + val_size]\n",
    "y_val = gmfd_train_reshaped[train_size:train_size + val_size]\n",
    "\n",
    "X_test = cmip6_train_reshaped[train_size + val_size:]\n",
    "y_test = gmfd_train_reshaped[train_size + val_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc1cf3-8a5c-4637-bd46-3e3bad547aa9",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2660e-5ca0-4b3b-938a-ba2c99e870be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(), loss='mean_squared_error')\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,  # Adjust as needed\n",
    "    batch_size=32,  # Adjust as needed\n",
    "    verbose=1  # To show the training process\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a87eb-e641-4ece-90c9-b66920127550",
   "metadata": {},
   "source": [
    "#### Define the hyperparameter grid and perform tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6522f507-3d1f-4099-a4da-665029a8330c",
   "metadata": {},
   "source": [
    "#### Evaluate the model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d550b4-5eb0-4455-96e7-349752f2981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Back-transform function\n",
    "def denormalize(data, mean, std):\n",
    "    return (data * std) + mean\n",
    "\n",
    "# Get the mean and std from the training set for denormalization\n",
    "cmip6_high_res_mean = cmip6_high_res['tas'].mean().values\n",
    "cmip6_high_res_std = cmip6_high_res['tas'].std().values\n",
    "\n",
    "# Get the mean and std from the training set for denormalization\n",
    "gmfd_mean = gmfd_data['tas'].mean().values\n",
    "gmfd_std = gmfd_data['tas'].std().values\n",
    "\n",
    "# # Evaluate on the denormalized test data\n",
    "# val_mse, val_mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "# print(f\"Validation MAE: {val_mae}\")\n",
    "# print(f\"Validation MSE: {val_mse}\")\n",
    "\n",
    "\n",
    "# Generate predictions on validation data\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "\n",
    "# Back-transform the predictions for evaluation\n",
    "y_val_denorm = denormalize(y_val, cmip6_high_res_mean, cmip6_high_res_std)\n",
    "y_pred_denorm = denormalize(y_pred, cmip6_high_res_mean, cmip6_high_res_std)\n",
    "\n",
    "# Plot: Predicted vs Actual Values (back-transformed)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_val_denorm.flatten(), y_pred_denorm.flatten(), alpha=0.5)\n",
    "plt.xlabel('Actual Values (GMFD)')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted vs Actual GMFD Values (Back-transformed)')\n",
    "plt.plot([y_val_denorm.min(), y_val_denorm.max()], [y_val_denorm.min(), y_val_denorm.max()], 'r--')  # Line of perfect prediction\n",
    "plt.show()\n",
    "\n",
    "# Plot: Residuals (Actual - Predicted) after back-transform\n",
    "residuals_denorm = y_val_denorm.flatten() - y_pred_denorm.flatten()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(residuals_denorm, bins=50, alpha=0.75, color='blue')\n",
    "plt.title('Residuals Distribution (Back-transformed)')\n",
    "plt.xlabel('Residuals (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plot: Predicted and Actual Values Over Time for a Specific Grid Cell (Back-transformed)\n",
    "# Select a grid cell (e.g., the first one)\n",
    "grid_cell_index = 3\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_val_denorm[:200, grid_cell_index, 0].flatten(), label='Actual (GMFD)')\n",
    "plt.plot(y_pred_denorm[:200, grid_cell_index, 0].flatten(), label='Predicted')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('tas Value (Back-transformed)')\n",
    "plt.title(f'Predicted vs Actual GMFD Values Over Time (Grid Cell {grid_cell_index})')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc5ae68-67a0-465e-8898-807f29cb218b",
   "metadata": {},
   "source": [
    "#### Train the Best Model on All Data\n",
    "Train the model on all the data (no splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1cb3e3-06d2-4b75-8b30-035e996cdef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (cmip6_train.shape[1], cmip6_train.shape[2], 1)  # Assuming 1 channel (tas)\n",
    "#model = model(input_shape)\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model on all the data (no splitting)\n",
    "history = model.fit(\n",
    "    cmip6_train_reshaped, gmfd_train_reshaped,\n",
    "    epochs=1500,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save('models/cnn_encoder_decoder_CNRM-ESM2-1.keras')  # keras format\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.title('Model Training Loss cnn_encoder_decoder_CNRM-ESM2-1')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f'png/cnn_encoder_decoder_CNRM-ESM2-1_training_loss_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()  # Close the figure to free memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c51fd0-9834-42a5-ae4e-20b9453d421d",
   "metadata": {},
   "source": [
    "#### Apply the Model to CMIP6 Data to Downscale to GMFD Original Resolution\n",
    "Now we take the coarse CMIP6 data and downscale it to the original GMFD resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f8134-b017-4e97-b799-5942a25ddd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from keras.models import load_model\n",
    "#model = load_model('models/cnn_encoder_decoder.keras')\n",
    "\n",
    "# Predict downscaled high-resolution data\n",
    "predicted_high_res = model.predict(cmip6_train_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb7e5b4-c415-4afb-8316-1c4246361354",
   "metadata": {},
   "source": [
    "#### Post-process the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fca6f8-cbce-4256-a9a9-319a68a591ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the predictions to get the actual temperature values\n",
    "\n",
    "\n",
    "# Get the mean and std from the training set for denormalization\n",
    "cmip6_high_res_mean = cmip6_high_res['tas'].mean().values\n",
    "cmip6_high_res_std = cmip6_high_res['tas'].std().values\n",
    "\n",
    "\n",
    "# Back-transform the predictions and actual values\n",
    "predicted_high_res_denorm = denormalize(predicted_high_res, cmip6_high_res_mean, cmip6_high_res_std)\n",
    "\n",
    "# Reshape the predictions to match the original GMFD resolution\n",
    "predicted_high_res_final = predicted_high_res_denorm.reshape(gmfd_train.shape)\n",
    "\n",
    "# Save the predictions to a NetCDF file\n",
    "predicted_ds = xr.DataArray(predicted_high_res_final, dims=gmfd_data.dims, coords=gmfd_data.coords, name='tas_downscaled')\n",
    "predicted_ds.to_netcdf('/data/keeling/a/ad87/downscale/predicted_high_res_tas_encod.nc')\n",
    "\n",
    "# #### Results saved to NetCDF format\n",
    "print(\"Downscaled high-resolution predictions saved to NetCDF format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab5f0c-4a5c-45ee-b8e3-5c3df6cc1546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
